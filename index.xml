<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ps126.5</title>
    <link>https://tjdoc.github.io/</link>
    <description>Recent content on ps126.5</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 18 Jan 2021 18:42:17 +0900</lastBuildDate><atom:link href="https://tjdoc.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Neural Networksand Deep Learning W2: Lab</title>
      <link>https://tjdoc.github.io/posts/2021-01-18-w2_lab/</link>
      <pubDate>Mon, 18 Jan 2021 18:42:17 +0900</pubDate>
      
      <guid>https://tjdoc.github.io/posts/2021-01-18-w2_lab/</guid>
      <description>packages import numpy as np import matplotlib.pyplot as plt import h5py import scipy from PIL import Image from scipy import ndimage from lr_utils import load_dataset %matplotlib inline load dataset import numpy as np import h5py def load_dataset(): train_dataset = h5py.File(&amp;#39;datasets/train_catvnoncat.h5&amp;#39;, &amp;#34;r&amp;#34;) train_set_x_orig = np.array(train_dataset[&amp;#34;train_set_x&amp;#34;][:]) # your train set features train_set_y_orig = np.array(train_dataset[&amp;#34;train_set_y&amp;#34;][:]) # your train set labels test_dataset = h5py.File(&amp;#39;datasets/test_catvnoncat.h5&amp;#39;, &amp;#34;r&amp;#34;) test_set_x_orig = np.array(test_dataset[&amp;#34;test_set_x&amp;#34;][:]) # your test set features test_set_y_orig = np.</description>
    </item>
    
    <item>
      <title>Coursera W2 Numpy Code</title>
      <link>https://tjdoc.github.io/posts/2021-01-18-coursera_w2_code/</link>
      <pubDate>Mon, 18 Jan 2021 14:57:04 +0900</pubDate>
      
      <guid>https://tjdoc.github.io/posts/2021-01-18-coursera_w2_code/</guid>
      <description>Sigmoid function import math import numpy as np def basic_sigmoid(x): return 1/(1+math.exp(-x)) def sigmoid(x) return 1/(1+np.exp(-x)) Derivative of sigmoid \[ \sigma &#39; (x) = \sigma(x)(1-\sigma(x)) \]
def sigmoid_derivative(x): s = sigmoid(x) ds = s*(1-s) return ds Reshaping arbitrary dimension numpy array to a column vector def image2vector(image): &amp;#34;&amp;#34;&amp;#34; Argument: image -- a numpy array of shape (length, height, depth) Returns: v -- a vector of shape (length*height*depth, 1) &amp;#34;&amp;#34;&amp;#34; # v = image.</description>
    </item>
    
    <item>
      <title>Galatians 6:9</title>
      <link>https://tjdoc.github.io/posts/2021-01-18-gal69/</link>
      <pubDate>Mon, 18 Jan 2021 00:18:49 +0900</pubDate>
      
      <guid>https://tjdoc.github.io/posts/2021-01-18-gal69/</guid>
      <description>NKRV gal 6:9 우리가 선을 행하되 낙심하지 말지니 포기하지 아니하면 때가 이르매 거두리라
CJB gal 6:9. So let us not grow weary of doing what is good; for if we don’t give up, we will in due time reap the harvest.
 Amen!</description>
    </item>
    
    <item>
      <title>Neural Networks and Deep Learning W2: Logistic Regression as a Neural Network</title>
      <link>https://tjdoc.github.io/posts/2021-01-15-coursera_w2/</link>
      <pubDate>Fri, 15 Jan 2021 10:52:30 +0900</pubDate>
      
      <guid>https://tjdoc.github.io/posts/2021-01-15-coursera_w2/</guid>
      <description>Logistic Regression Given x, we want \({\hat y} = P(y=1 |_x)\) where
input vector: \( x \in \Re^{n_x} \)
Parameters: \(w \in \Re^{n_x}\), \(b \in \Re \)
Output: \({\hat y} = \sigma (w^T x + b)\)
Here, \( \sigma(z) = \frac{1}{1+e^{-z}} \) is the sigmoid function that enforces \( 0 \le {\hat y} \le 1 \)
Given \( \{{ (x^{(1)} , y^{(1)}) , &amp;hellip;, (x^{(m)} , y^{(m)}) \}} \)
we want \( {\hat y}^{(i)} \approx y^{(i)} \)</description>
    </item>
    
    <item>
      <title>Psalm 20</title>
      <link>https://tjdoc.github.io/posts/2021-01-15-ps20/</link>
      <pubDate>Fri, 15 Jan 2021 08:47:21 +0900</pubDate>
      
      <guid>https://tjdoc.github.io/posts/2021-01-15-ps20/</guid>
      <description>For the leader. A psalm of David: May Adonai answer you in times of distress, may the name of the God of Ya‘akov protect you. May he send you help from the sanctuary and give you support from Tziyon. May he be reminded by all your grain offerings and accept the fat of your burnt offerings. (Selah) May he grant you your heart’s desire and bring all your plans to success.</description>
    </item>
    
    <item>
      <title>sleep</title>
      <link>https://tjdoc.github.io/posts/2021-01-15-sleep/</link>
      <pubDate>Fri, 15 Jan 2021 05:52:58 +0900</pubDate>
      
      <guid>https://tjdoc.github.io/posts/2021-01-15-sleep/</guid>
      <description>NKRV ps 127:2. 너희가 일찍이 일어나고 늦게 누우며 수고의 떡을 먹음이 헛되도다 그러므로 여호와께서 그의 사랑하시는 자에게는 잠을 주시는도다
  KJV ps 127:2. It is vain for you to rise up early, to sit up late, to eat the bread of sorrows: for so he giveth his beloved sleep.
  CJB ps 127:2. In vain do you get up early and put off going to bed, working hard to earn a living; for he provides for his beloved, even when they sleep.</description>
    </item>
    
    <item>
      <title>Neural Networks and Deep Learning W1: What is a neural network?</title>
      <link>https://tjdoc.github.io/posts/2021-01-14-coursera_w1/</link>
      <pubDate>Thu, 14 Jan 2021 21:06:56 +0900</pubDate>
      
      <guid>https://tjdoc.github.io/posts/2021-01-14-coursera_w1/</guid>
      <description>Terminology  x: input y: output Deep Learning: Same thing as Neural Network but sounds better brandwise  Application Standard Neural Network
 Real estate Online Advertising  Convolutional NN (CNN)
 Image data Photo tagging  Recurrent NN (RNN)
 Data invoving temporal component Speech recognition Machine transaltion  Custom Hybrid
 Automous driving  Data kinds  Supervised Data: Database Unstructured Data  audio image text    Why is deep learning taking off?</description>
    </item>
    
    <item>
      <title>Start</title>
      <link>https://tjdoc.github.io/posts/2021-01-14-start/</link>
      <pubDate>Thu, 14 Jan 2021 02:38:37 +0900</pubDate>
      
      <guid>https://tjdoc.github.io/posts/2021-01-14-start/</guid>
      <description>They that sow in tears shall reap in joy. ps 126:5
 start</description>
    </item>
    
  </channel>
</rss>
