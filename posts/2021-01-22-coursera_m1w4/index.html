<!DOCTYPE html>
<html lang="en">

<head>
    
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
<meta name="HandheldFriendly" content="True" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
<meta name="generator" content="Hugo 0.80.0" />


<link rel="shortcut icon" href="https://cdn.jsdelivr.net/gh/amzrk2/cdn-stcapi@1/favicons/favicon.ico" />


<title>Neural Networks and Deep Learning W4: Deepl L-layer neural network - ps126.5</title>




<meta name="keywords" content="coursera, neural network" />


<meta property="og:title" content="Neural Networks and Deep Learning W4: Deepl L-layer neural network" />
<meta name="twitter:title" content="Neural Networks and Deep Learning W4: Deepl L-layer neural network" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://tjdoc.github.io/posts/2021-01-22-coursera_m1w4/" /><meta property="og:description" content="Terminology  L number of layers \(n^{[l]}\) number of units in layer l \(a^{[l]}\) activations in layer l, \( a^{[l]} = g^{[l]} (z^{[l]}) \)  Forward propagation in deep network $$ \begin{aligned} Z^{[l]} =&amp; W^{[l]} A^{[l-1]} &#43; b^{[l]} \\ A^{[l]} =&amp; g^{[l]} (Z^{[l]}) \end{aligned} $$
where \( A^{[0]} = X \)
You will need an explict for-loop for computing each layers.
Getting your matrix dimensions right $$ \begin{aligned} W^{[l]} &amp;: (n^{[l]}, n^{[l-1]}) \\ b^{[l]} &amp;: (n^{[l]}, 1) \\ dW^{[l]} &amp;: (n^{[l]}, n^{[l-1]}) \\ db^{[l]} &amp;: (n^{[l]}, 1) \\ \end{aligned} $$" />
<meta name="twitter:description" content="Terminology  L number of layers \(n^{[l]}\) number of units in layer l \(a^{[l]}\) activations in layer l, \( a^{[l]} = g^{[l]} (z^{[l]}) \)  Forward propagation in deep network $$ \begin{aligned} Z^{[l]} =&amp; W^{[l]} A^{[l-1]} &#43; b^{[l]} \\ A^{[l]} =&amp; g^{[l]} (Z^{[l]}) \end{aligned} $$
where \( A^{[0]} = X \)
You will need an explict for-loop for computing each layers.
Getting your matrix dimensions right $$ \begin{aligned} W^{[l]} &amp;: (n^{[l]}, n^{[l-1]}) \\ b^{[l]} &amp;: (n^{[l]}, 1) \\ dW^{[l]} &amp;: (n^{[l]}, n^{[l-1]}) \\ db^{[l]} &amp;: (n^{[l]}, 1) \\ \end{aligned} $$" /><meta name="twitter:card" content="summary" /><meta property="article:published_time" content="2021-01-22T16:13:24+09:00" /><meta property="article:modified_time" content="2021-01-22T16:13:24+09:00" />


<style>
    @media (prefers-color-scheme: dark) {
        body[data-theme='auto'] img {
            filter: brightness(60%);
        }
    }

    body[data-theme='dark'] img {
        filter: brightness(60%);
    }
</style>



<link rel="stylesheet" href="https://tjdoc.github.io/assets/css/fuji.min.css" />





</head>

<body data-theme="auto">
    <script data-cfasync="false">
  
  var fujiThemeData = localStorage.getItem('fuji_data-theme');
  
  if (!fujiThemeData) {
    localStorage.setItem('fuji_data-theme', 'auto');
  } else {
    
    if (fujiThemeData !== 'auto') {
      document.body.setAttribute('data-theme', fujiThemeData === 'dark' ? 'dark' : 'light');
    }
  }
</script>
    <header>
    <div class="container-lg clearfix">
        <div class="col-12 header">
            <a class="title-main" href="https://tjdoc.github.io/">ps126.5</a>
            
        </div>
    </div>
</header>

    <main>
        <div class="container-lg clearfix">
            
            <div class="col-12 col-md-9 float-left content">
                
<article>
    
    <h2 class="post-item post-title">
        <a href="https://tjdoc.github.io/posts/2021-01-22-coursera_m1w4/">Neural Networks and Deep Learning W4: Deepl L-layer neural network</a>
    </h2>
    <div class="post-item post-meta">
        <span><i class="iconfont icon-today-sharp"></i>&nbsp;2021-01-22</span><span><i class="iconfont icon-pricetags-sharp"></i>&nbsp;<a href="/tags/coursera">coursera</a>&nbsp;<a href="/tags/neural-network">neural network</a>&nbsp;</span>

    </div>
    
    <div class="post-content markdown-body">
        <h2 id="terminology">Terminology</h2>
<dl>
<dt>L</dt>
<dd>number of layers</dd>
<dt>\(n^{[l]}\)</dt>
<dd>number of units in layer l</dd>
<dt>\(a^{[l]}\)</dt>
<dd>activations in layer l, \( a^{[l]} = g^{[l]} (z^{[l]}) \)</dd>
</dl>
<h2 id="forward-propagation-in-deep-network">Forward propagation in deep network</h2>
<p>$$
\begin{aligned}
Z^{[l]} =&amp; W^{[l]} A^{[l-1]} + b^{[l]} \\
A^{[l]} =&amp; g^{[l]} (Z^{[l]})
\end{aligned}
$$</p>
<p>where \( A^{[0]} = X \)</p>
<p>You will need an explict for-loop for computing each layers.</p>
<h2 id="getting-your-matrix-dimensions-right">Getting your matrix dimensions right</h2>
<p>$$
\begin{aligned}
W^{[l]} &amp;: (n^{[l]}, n^{[l-1]}) \\
b^{[l]} &amp;: (n^{[l]}, 1) \\
dW^{[l]} &amp;: (n^{[l]}, n^{[l-1]}) \\
db^{[l]} &amp;: (n^{[l]}, 1) \\
\end{aligned}
$$</p>
<p><img class="img-zoomable" src="/coursera/mat_dimension.jpeg" alt="matrix dimension" />
</p>
<p>correction: in the upper left side of the figure, a and z should be swapped, i.e., it should be</p>
<p>$$ a^{[l]} = g^{[l]}(z^{[l]}) $$</p>
<h3 id="vectorized-implementation">Vectorized implementation</h3>
<p>$$
\begin{aligned}
Z^{[l]}, A^{[l]} &amp;: (n^{[l]}, m) \\
l=0, A^{[0]} = X &amp;: (n^{[0]}, m) \\
dZ^{[l]}, dA^{[l]} &amp;: (n^{[l]}, m)
\end{aligned}
$$</p>
<p><img class="img-zoomable" src="/coursera/mat_dimension.jpeg" alt="matrix dimension" />
</p>
<h2 id="building-blocks-of-deep-neural-networks">building blocks of deep neural networks</h2>
<p><img class="img-zoomable" src="/coursera/fb_dl.jpeg" alt="forward backward propagation building blocks" />
</p>
<p><img class="img-zoomable" src="/coursera/fb_dl2.jpeg" alt="forward backward propagation building blocks 2" />
</p>
<p><img class="img-zoomable" src="/coursera/forward_step.jpeg" alt="forward step" />
</p>
<p><img class="img-zoomable" src="/coursera/backward_step.jpeg" alt="backward step" />
</p>
<p>correction: \(dw^{[l]} = dz^{[l]} * a^{[l-1]T} \) : a should be transposed</p>
<p><img class="img-zoomable" src="/coursera/fb_summary.jpeg" alt="forward backward summary" />
</p>
<blockquote>
<p>A lot of complexity of your learning algorith comes from the data rather than necessarily from your writing thousands and thousands of lines of code.</p>
</blockquote>
<h3 id="forward-propagation">Forward Propagation</h3>
<p>$$
\begin{aligned}
Z^{[1]} &amp;= W^{[1]} X + b^{[1]} \\
A^{[1]} &amp;= g^{[1]} (Z^{[1]}) \\
Z^{[2]} &amp;= W^{[2]} A^{[1]} + b^{[2]} \\
A^{[2]} &amp;= g^{[2]} (Z^{[2]}) \\
&amp; \qquad \vdots \\
A^{[L]} &amp;= g^{[L]} (Z^{[L]}) = {\hat Y}
\end{aligned}
$$</p>
<h3 id="backward-propagation">Backward Propagation</h3>
<p>$$
\begin{aligned}
dZ^{[L]} &amp;= A^{[L]} -Y \\
dW^{[L]} &amp;= \frac{1}{m} dZ^{[L]} A^{[L-1]T} \\
db^{[L]} &amp;= \frac{1}{m} np.sum (dZ^{[L]}, axis = 1, keepdims = True) \\
dZ^{[L-1]} &amp;= W^{[L]T} dZ^{[L]} * g'^{[L-1]}(Z^{[L-1]}) \\
&amp; \qquad \vdots \\
dZ^{[1]} &amp;= W^{[2]} dZ^{[2]} * g'^{[1]} (Z^{[1]}) \\
dW^{[1]} &amp;= \frac{1}{m} dZ^{[1]} A^{[0]T} \\
db^{[1]} &amp;= \frac{1}{m} np.sum (dZ^{[1]}, axis = 1, keepdims = True) \\
\end{aligned}
$$</p>
<h2 id="parameters-vs-hyperparameters">Parameters vs Hyperparameters</h2>
<p>Parameters: \( W^{[1]}, b^{[1]}, W^{[2]}, b^{[2]}, W^{[3]}, b^{[3]}, \cdots \)</p>
<p>Hyperparameters:</p>
<ul>
<li>learning rate \(\alpha\)</li>
<li>number of iterations</li>
<li>number of hidden layers</li>
<li>hidden units \(n^{[1]}, n^{[2]}, \cdots\)</li>
<li>choice of activation function</li>
</ul>
<p>Other hyperparameters</p>
<ul>
<li>momentum terms</li>
<li>minibatch size</li>
<li>regularizations</li>
</ul>
<h2 id="applied-deep-learning-is-a-very-empirical-process">Applied deep learning is a very empirical process</h2>
<p>determining the learning rate: try different values and monitor the evolution of the cost function value J</p>

    </div>
</article>




            </div>
            <aside class="col-12 col-md-3 float-left sidebar">
    
    <div class="sidebar-item sidebar-pages">
        <h3>Pages</h3>
        <ul>
            
        </ul>
    </div>
    
    <div class="sidebar-item sidebar-links">
        <h3>Links</h3>
        <ul>
            
        </ul>
    </div>
    
    <div class="sidebar-item sidebar-tags">
        <h3>Tags</h3>
        <div>
            
            <span>
                <a href="/tags/coursera/">coursera</a>
            </span>
            
            <span>
                <a href="/tags/neural-network/">neural network</a>
            </span>
            
            <span>
                <a href="/tags/reflection/">reflection</a>
            </span>
            
        </div>
    </div>
    <div class="sidebar-item sidebar-toc">
        <h3>TOC</h3><nav id="TableOfContents">
  <ul>
    <li><a href="#terminology">Terminology</a></li>
    <li><a href="#forward-propagation-in-deep-network">Forward propagation in deep network</a></li>
    <li><a href="#getting-your-matrix-dimensions-right">Getting your matrix dimensions right</a>
      <ul>
        <li><a href="#vectorized-implementation">Vectorized implementation</a></li>
      </ul>
    </li>
    <li><a href="#building-blocks-of-deep-neural-networks">building blocks of deep neural networks</a>
      <ul>
        <li><a href="#forward-propagation">Forward Propagation</a></li>
        <li><a href="#backward-propagation">Backward Propagation</a></li>
      </ul>
    </li>
    <li><a href="#parameters-vs-hyperparameters">Parameters vs Hyperparameters</a></li>
    <li><a href="#applied-deep-learning-is-a-very-empirical-process">Applied deep learning is a very empirical process</a></li>
  </ul>
</nav></div>
</aside>
        </div>
        <div class="btn">
    <div class="btn-menu" id="btn-menu">
        <i class="iconfont icon-grid-sharp"></i>
    </div>
    <div class="btn-toggle-mode">
        <i class="iconfont icon-contrast-sharp"></i>
    </div>
    <div class="btn-scroll-top">
        <i class="iconfont icon-chevron-up-circle-sharp"></i>
    </div>
</div>
<aside class="sidebar-mobile" style="display: none;">
  <div class="sidebar-wrapper">
    
    <div class="sidebar-item sidebar-pages">
        <h3>Pages</h3>
        <ul>
            
        </ul>
    </div>
    
    <div class="sidebar-item sidebar-links">
        <h3>Links</h3>
        <ul>
            
        </ul>
    </div>
    
    <div class="sidebar-item sidebar-tags">
        <h3>Tags</h3>
        <div>
            
            <span>
                <a href="/tags/coursera/">coursera</a>
            </span>
            
            <span>
                <a href="/tags/neural-network/">neural network</a>
            </span>
            
            <span>
                <a href="/tags/reflection/">reflection</a>
            </span>
            
        </div>
    </div>
    
    
    
    
  </div>
</aside>
    </main>

    <footer>
    <div class="container-lg clearfix">
        <div class="col-12 footer">
            
            <span>&copy; 2021
                <a href="https://tjdoc.github.io/"></a>
                
                | Powered by <a href="https://github.com/amzrk2/hugo-theme-fuji/"
                   target="_blank">Fuji-v2</a> &amp; <a href="https://gohugo.io/"
                                                    target="_blank">Hugo</a> 
            </span>
        </div>
    </div>
</footer>

    
<script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js"></script>
<script defer src="https://cdn.jsdelivr.net/npm/lazysizes@5.3.0/lazysizes.min.js"></script>
<script defer src="https://cdn.jsdelivr.net/npm/prismjs@1.23.0/components/prism-core.min.js"></script>
<script defer src="https://cdn.jsdelivr.net/npm/prismjs@1.23.0/plugins/autoloader/prism-autoloader.min.js"></script>



<script defer src="/assets/js/fuji.min.js"></script>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" />
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js"></script>
<script
  defer
  src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js"
  onload="renderMathInElement(document.body);"
></script>



</body>

</html>